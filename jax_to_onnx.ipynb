{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from dataclasses import asdict\n",
    "import jax.tree_util as tree\n",
    "import numpy as np\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39242/3522588695.py:5: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
      "  params_jax = jax.tree_map(jnp.array, params_loaded)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params successfully loaded\n"
     ]
    }
   ],
   "source": [
    "with open(\"utils/weights/go2_params.pkl\", \"rb\") as f:\n",
    "    params_loaded = pickle.load(f)\n",
    "\n",
    "# Convert back to JAX arrays if needed\n",
    "params_jax = jax.tree_map(jnp.array, params_loaded)\n",
    "\n",
    "print(\"Params successfully loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_all = asdict(params_loaded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': {'privileged_state': array([-5.37527027e-03, -3.72266746e-03,  8.12138896e-03,  2.57836631e-03,\n",
       "         -6.08543726e-03, -1.65748596e-03,  6.04978902e-03, -1.80347846e-03,\n",
       "         -9.96224463e-01,  9.29868402e-05,  2.46114898e-02,  1.09104462e-01,\n",
       "          1.61302444e-02,  1.28113348e-02,  9.11557004e-02, -1.92847494e-02,\n",
       "          9.35180578e-03,  1.01881891e-01,  3.81241962e-02,  2.00909637e-02,\n",
       "          8.42443928e-02, -4.69057495e-03,  8.90833884e-03, -2.58548930e-02,\n",
       "          5.94130391e-03,  9.43633262e-03, -2.62726732e-02, -6.10564649e-03,\n",
       "          4.42138221e-03, -2.11185254e-02,  6.94550341e-03, -1.06999592e-03,\n",
       "         -6.93152659e-03, -2.30879664e-01, -3.03159729e-02,  5.01185060e-01,\n",
       "          2.54054993e-01, -1.06226727e-02,  5.21934569e-01, -2.14919150e-01,\n",
       "          5.40529490e-02,  4.64715093e-01,  2.54152119e-01,  3.86505276e-02,\n",
       "          4.87904727e-01, -2.90122745e-03, -7.52538326e-04, -1.18151722e-04,\n",
       "          2.57487851e-03, -6.08745031e-03, -1.66083185e-03, -6.34295940e-02,\n",
       "          1.93015039e-02,  9.86343193e+00,  6.05144491e-03, -1.80784287e-03,\n",
       "         -9.96222079e-01, -5.37372334e-03, -3.72343045e-03,  8.12281761e-03,\n",
       "          2.19086258e-04, -2.45903939e-05, -1.75158237e-03,  9.29678135e-05,\n",
       "          2.46096905e-02,  1.09103695e-01,  1.61310807e-02,  1.28117474e-02,\n",
       "          9.11559388e-02, -1.92857049e-02,  9.35228448e-03,  1.01882853e-01,\n",
       "          3.81242633e-02,  2.00890303e-02,  8.42425749e-02, -4.69057495e-03,\n",
       "          8.90833884e-03, -2.58548930e-02,  5.94130391e-03,  9.43633262e-03,\n",
       "         -2.62726732e-02, -6.10564649e-03,  4.42138221e-03, -2.11185254e-02,\n",
       "          6.94550341e-03, -1.06999592e-03, -6.93152659e-03,  2.39437032e+00,\n",
       "         -9.77759302e-01,  5.57993841e+00, -2.55621386e+00, -1.04589677e+00,\n",
       "          5.31501579e+00,  1.90409875e+00,  2.43042961e-01,  5.18611431e+00,\n",
       "         -1.87667167e+00,  3.49903613e-01,  4.97258663e+00,  8.89850080e-01,\n",
       "          8.89649868e-01,  8.66836429e-01,  8.66916060e-01,  9.25673739e-05,\n",
       "          2.49657296e-05,  1.17132356e-02,  1.65150064e-04, -2.99404892e-05,\n",
       "          1.13706933e-02,  1.17840180e-04,  1.24235783e-04,  8.55765678e-03,\n",
       "          2.11092614e-04,  6.26547117e-05,  9.13883373e-03,  2.55512260e-02,\n",
       "          2.56797802e-02,  2.73064021e-02,  2.74053868e-02,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00], dtype=float32),\n",
       "  'state': array([-5.3752703e-03, -3.7226675e-03,  8.1213890e-03,  2.5783663e-03,\n",
       "         -6.0854373e-03, -1.6574860e-03,  6.0497890e-03, -1.8034785e-03,\n",
       "         -9.9622446e-01,  9.2986840e-05,  2.4611490e-02,  1.0910446e-01,\n",
       "          1.6130244e-02,  1.2811335e-02,  9.1155700e-02, -1.9284749e-02,\n",
       "          9.3518058e-03,  1.0188189e-01,  3.8124196e-02,  2.0090964e-02,\n",
       "          8.4244393e-02, -4.6905749e-03,  8.9083388e-03, -2.5854893e-02,\n",
       "          5.9413039e-03,  9.4363326e-03, -2.6272673e-02, -6.1056465e-03,\n",
       "          4.4213822e-03, -2.1118525e-02,  6.9455034e-03, -1.0699959e-03,\n",
       "         -6.9315266e-03, -2.3087966e-01, -3.0315973e-02,  5.0118506e-01,\n",
       "          2.5405499e-01, -1.0622673e-02,  5.2193457e-01, -2.1491915e-01,\n",
       "          5.4052949e-02,  4.6471509e-01,  2.5415212e-01,  3.8650528e-02,\n",
       "          4.8790473e-01, -2.9012274e-03, -7.5253833e-04, -1.1815172e-04],\n",
       "        dtype=float32)},\n",
       " 'std': {'privileged_state': array([3.68186742e-01, 1.37561753e-01, 1.47242501e-01, 8.58022928e-01,\n",
       "         4.78526682e-01, 5.59886336e-01, 5.72714731e-02, 6.88533783e-02,\n",
       "         4.45153564e-02, 1.03283904e-01, 1.17335930e-01, 1.26863018e-01,\n",
       "         1.08773708e-01, 1.20154835e-01, 1.28264025e-01, 9.03791487e-02,\n",
       "         1.26876995e-01, 1.36384159e-01, 9.31495801e-02, 1.21340334e-01,\n",
       "         1.32952452e-01, 1.91393936e+00, 2.79873967e+00, 3.60948825e+00,\n",
       "         1.94568717e+00, 2.84290719e+00, 3.84499931e+00, 1.91580844e+00,\n",
       "         3.09077668e+00, 3.55464578e+00, 1.98109519e+00, 3.00418591e+00,\n",
       "         3.64060020e+00, 2.24448130e-01, 2.63447136e-01, 3.06280017e-01,\n",
       "         2.24987045e-01, 2.62715846e-01, 2.92039156e-01, 2.17981443e-01,\n",
       "         2.51816392e-01, 2.93652445e-01, 2.01654717e-01, 2.59575337e-01,\n",
       "         3.02575827e-01, 8.30465615e-01, 2.87504226e-01, 5.34165859e-01,\n",
       "         8.50218356e-01, 4.64383572e-01, 5.47853172e-01, 1.66907144e+00,\n",
       "         3.05355501e+00, 4.78473473e+00, 4.94630635e-02, 6.25102520e-02,\n",
       "         3.38876620e-02, 3.63631010e-01, 1.24858022e-01, 1.35448575e-01,\n",
       "         6.78959548e-01, 6.78873301e-01, 5.62897503e-01, 1.01821475e-01,\n",
       "         1.16049089e-01, 1.25673085e-01, 1.07386045e-01, 1.18902721e-01,\n",
       "         1.27089888e-01, 8.87045786e-02, 1.25687182e-01, 1.35281086e-01,\n",
       "         9.15225595e-02, 1.20098941e-01, 1.31818533e-01, 1.91393936e+00,\n",
       "         2.79873967e+00, 3.60948825e+00, 1.94568717e+00, 2.84290719e+00,\n",
       "         3.84499931e+00, 1.91580844e+00, 3.09077668e+00, 3.55464578e+00,\n",
       "         1.98109519e+00, 3.00418591e+00, 3.64060020e+00, 3.80331898e+00,\n",
       "         5.15827417e+00, 4.86593294e+00, 3.72782826e+00, 5.17281723e+00,\n",
       "         4.71879864e+00, 3.64966154e+00, 4.27369452e+00, 4.89759588e+00,\n",
       "         3.48701310e+00, 4.34275246e+00, 4.71187496e+00, 3.13076973e-01,\n",
       "         3.13326269e-01, 3.39751542e-01, 3.39665473e-01, 6.25933230e-01,\n",
       "         6.26030624e-01, 4.92480874e-01, 6.32684469e-01, 6.32447243e-01,\n",
       "         4.51879382e-01, 5.93387485e-01, 5.93323946e-01, 4.82725352e-01,\n",
       "         5.95841110e-01, 5.95905721e-01, 4.66008723e-01, 2.44227853e-02,\n",
       "         2.56060511e-02, 2.68288497e-02, 2.64130421e-02, 9.99999997e-07,\n",
       "         9.99999997e-07, 9.99999997e-07, 9.99999997e-07], dtype=float32),\n",
       "  'state': array([0.36818674, 0.13756175, 0.1472425 , 0.8580229 , 0.47852668,\n",
       "         0.55988634, 0.05727147, 0.06885338, 0.04451536, 0.1032839 ,\n",
       "         0.11733593, 0.12686302, 0.10877371, 0.12015484, 0.12826402,\n",
       "         0.09037915, 0.126877  , 0.13638416, 0.09314958, 0.12134033,\n",
       "         0.13295245, 1.9139394 , 2.7987397 , 3.6094882 , 1.9456872 ,\n",
       "         2.8429072 , 3.8449993 , 1.9158084 , 3.0907767 , 3.5546458 ,\n",
       "         1.9810952 , 3.004186  , 3.6406002 , 0.22444813, 0.26344714,\n",
       "         0.30628002, 0.22498704, 0.26271585, 0.29203916, 0.21798144,\n",
       "         0.2518164 , 0.29365245, 0.20165472, 0.25957534, 0.30257583,\n",
       "         0.8304656 , 0.28750423, 0.53416586], dtype=float32)},\n",
       " 'count': array(2.0054016e+08, dtype=float32),\n",
       " 'summed_variance': {'privileged_state': array([2.7185520e+07, 3.7948688e+06, 4.3477820e+06, 1.4763835e+08,\n",
       "         4.5921248e+07, 6.2863876e+07, 6.5777612e+05, 9.5071838e+05,\n",
       "         3.9739375e+05, 2.1392750e+06, 2.7609808e+06, 3.2275385e+06,\n",
       "         2.3727348e+06, 2.8952355e+06, 3.2992185e+06, 1.6380902e+06,\n",
       "         3.2282500e+06, 3.7301752e+06, 1.7400558e+06, 2.9526482e+06,\n",
       "         3.5448195e+06, 7.3461146e+08, 1.5708197e+09, 2.6127186e+09,\n",
       "         7.5918458e+08, 1.6207899e+09, 2.9647895e+09, 7.3604698e+08,\n",
       "         1.9157403e+09, 2.5339267e+09, 7.8706758e+08, 1.8099016e+09,\n",
       "         2.6579533e+09, 1.0102605e+07, 1.3918369e+07, 1.8812162e+07,\n",
       "         1.0151176e+07, 1.3841205e+07, 1.7103444e+07, 9.5288490e+06,\n",
       "         1.2716552e+07, 1.7292932e+07, 8.1548910e+06, 1.3512265e+07,\n",
       "         1.8359878e+07, 1.3830717e+08, 1.6576386e+07, 5.7220760e+07,\n",
       "         1.4496472e+08, 4.3246908e+07, 6.0190748e+07, 5.5866470e+08,\n",
       "         1.8698760e+09, 4.5911035e+09, 4.9064050e+05, 7.8361694e+05,\n",
       "         2.3029503e+05, 2.6516924e+07, 3.1263258e+06, 3.6791735e+06,\n",
       "         9.2446224e+07, 9.2422736e+07, 6.3541876e+07, 2.0791228e+06,\n",
       "         2.7007528e+06, 3.1672762e+06, 2.3125818e+06, 2.8352080e+06,\n",
       "         3.2390925e+06, 1.5779506e+06, 3.1679862e+06, 3.6700798e+06,\n",
       "         1.6798002e+06, 2.8925422e+06, 3.4846108e+06, 7.3461146e+08,\n",
       "         1.5708197e+09, 2.6127186e+09, 7.5918458e+08, 1.6207899e+09,\n",
       "         2.9647895e+09, 7.3604698e+08, 1.9157403e+09, 2.5339267e+09,\n",
       "         7.8706758e+08, 1.8099016e+09, 2.6579533e+09, 2.9008607e+09,\n",
       "         5.3359309e+09, 4.7482506e+09, 2.7868472e+09, 5.3660611e+09,\n",
       "         4.4654397e+09, 2.6712008e+09, 3.6627592e+09, 4.8102456e+09,\n",
       "         2.4384202e+09, 3.7820869e+09, 4.4523459e+09, 1.9656382e+07,\n",
       "         1.9687700e+07, 2.3148572e+07, 2.3136846e+07, 7.8570112e+07,\n",
       "         7.8594560e+07, 4.8638492e+07, 8.0274144e+07, 8.0213960e+07,\n",
       "         4.0949292e+07, 7.0611936e+07, 7.0596824e+07, 4.6730624e+07,\n",
       "         7.1197104e+07, 7.1212544e+07, 4.3550132e+07, 1.1961668e+05,\n",
       "         1.3148814e+05, 1.4434625e+05, 1.3990661e+05, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00], dtype=float32),\n",
       "  'state': array([2.7185520e+07, 3.7948688e+06, 4.3477820e+06, 1.4763835e+08,\n",
       "         4.5921248e+07, 6.2863876e+07, 6.5777612e+05, 9.5071838e+05,\n",
       "         3.9739375e+05, 2.1392750e+06, 2.7609808e+06, 3.2275385e+06,\n",
       "         2.3727348e+06, 2.8952355e+06, 3.2992185e+06, 1.6380902e+06,\n",
       "         3.2282500e+06, 3.7301752e+06, 1.7400558e+06, 2.9526482e+06,\n",
       "         3.5448195e+06, 7.3461146e+08, 1.5708197e+09, 2.6127186e+09,\n",
       "         7.5918458e+08, 1.6207899e+09, 2.9647895e+09, 7.3604698e+08,\n",
       "         1.9157403e+09, 2.5339267e+09, 7.8706758e+08, 1.8099016e+09,\n",
       "         2.6579533e+09, 1.0102605e+07, 1.3918369e+07, 1.8812162e+07,\n",
       "         1.0151176e+07, 1.3841205e+07, 1.7103444e+07, 9.5288490e+06,\n",
       "         1.2716552e+07, 1.7292932e+07, 8.1548910e+06, 1.3512265e+07,\n",
       "         1.8359878e+07, 1.3830717e+08, 1.6576386e+07, 5.7220760e+07],\n",
       "        dtype=float32)}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_bias = params_loaded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hidden_0', 'hidden_1', 'hidden_2', 'hidden_3'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_bias[\"params\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bias', 'kernel'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_bias[\"params\"]['hidden_0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_bias[\"params\"]['hidden_0']['bias'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_bias[\"params\"]['hidden_0']['kernel'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layer_sizes,\n",
    "        activation=nn.ReLU(),\n",
    "        kernel_init=\"lecun_uniform\",\n",
    "        activate_final=False,\n",
    "        bias=True,\n",
    "        layer_norm=False,\n",
    "        mean_std=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.activation = activation\n",
    "        self.kernel_init = kernel_init\n",
    "        self.activate_final = activate_final\n",
    "        self.bias = bias\n",
    "        self.layer_norm = layer_norm\n",
    "\n",
    "        # Register mean and std as buffers (non-trainable parameters)\n",
    "        if mean_std is not None:\n",
    "            self.register_buffer(\"mean\", torch.tensor(mean_std[0], dtype=torch.float32))\n",
    "            self.register_buffer(\"std\", torch.tensor(mean_std[1], dtype=torch.float32))\n",
    "        else:\n",
    "            self.mean = None\n",
    "            self.std = None\n",
    "\n",
    "        # Build the MLP block\n",
    "        self.mlp_block = nn.Sequential()\n",
    "        for i in range(len(self.layer_sizes) - 1):\n",
    "            in_features = self.layer_sizes[i]\n",
    "            out_features = self.layer_sizes[i + 1]\n",
    "\n",
    "            # Add linear layer\n",
    "            dense_layer = nn.Linear(in_features, out_features, bias=self.bias)\n",
    "            self.mlp_block.add_module(f\"hidden_{i}\", dense_layer)\n",
    "\n",
    "            # Initialize weights (e.g., Lecun uniform initialization)\n",
    "            if self.kernel_init == \"lecun_uniform\":\n",
    "                nn.init.kaiming_uniform_(dense_layer.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "            # Add layer normalization if enabled\n",
    "            if self.layer_norm and i < len(self.layer_sizes) - 2:  # No layer norm after the last layer\n",
    "                self.mlp_block.add_module(f\"layer_norm_{i}\", nn.LayerNorm(out_features))\n",
    "\n",
    "            # Add activation function, except for the final layer if `activate_final` is False\n",
    "            if i < len(self.layer_sizes) - 2 or self.activate_final:  # Add activation for all but the last layer\n",
    "                self.mlp_block.add_module(f\"activation_{i}\", self.activation)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Handle list inputs\n",
    "        if isinstance(inputs, list):\n",
    "            inputs = inputs[0]\n",
    "\n",
    "        # Normalize inputs if mean and std are provided\n",
    "        if self.mean is not None and self.std is not None:\n",
    "            inputs = (inputs - self.mean) / self.std\n",
    "\n",
    "        # Pass through the MLP block\n",
    "        logits = self.mlp_block(inputs)\n",
    "\n",
    "        # Split the output into two parts and apply tanh to the first half\n",
    "        loc, _ = torch.split(logits, logits.size(-1) // 2, dim=-1)\n",
    "        return torch.tanh(loc)\n",
    "\n",
    "def make_policy_network(\n",
    "    observation_size,\n",
    "    action_size,\n",
    "    mean_std,\n",
    "    hidden_layer_sizes=[256, 256],\n",
    "    activation=nn.ReLU(),\n",
    "    kernel_init=\"lecun_uniform\",\n",
    "    layer_norm=False,\n",
    "):\n",
    "    layers = hidden_layer_sizes + [action_size]\n",
    "    print(layers)\n",
    "    policy_network = MLP(\n",
    "        layer_sizes= layers,\n",
    "        activation=activation,\n",
    "        kernel_init=kernel_init,\n",
    "        layer_norm=layer_norm,\n",
    "        mean_std=mean_std,\n",
    "    )\n",
    "    return policy_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std = (torch.tensor(mean_std_all['mean']['state']), torch.tensor(mean_std_all['std']['state']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48, 512, 256, 128, 24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39242/1165096672.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"mean\", torch.tensor(mean_std[0], dtype=torch.float32))\n",
      "/tmp/ipykernel_39242/1165096672.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"std\", torch.tensor(mean_std[1], dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "th_policy_network = make_policy_network(\n",
    "    observation_size = 48,\n",
    "    action_size = 12*2,\n",
    "    mean_std=mean_std,\n",
    "    hidden_layer_sizes=[48,512, 256, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (activation): SiLU()\n",
       "  (mlp_block): Sequential(\n",
       "    (hidden_0): Linear(in_features=48, out_features=512, bias=True)\n",
       "    (activation_0): SiLU()\n",
       "    (hidden_1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (activation_1): SiLU()\n",
       "    (hidden_2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (activation_2): SiLU()\n",
       "    (hidden_3): Linear(in_features=128, out_features=24, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_policy_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Original weights: torch.Size([512, 48])\n",
      "Original biases: torch.Size([512])\n",
      "Layer 2:\n",
      "Original weights: torch.Size([256, 512])\n",
      "Original biases: torch.Size([256])\n",
      "Layer 4:\n",
      "Original weights: torch.Size([128, 256])\n",
      "Original biases: torch.Size([128])\n",
      "Layer 6:\n",
      "Original weights: torch.Size([24, 128])\n",
      "Original biases: torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "# Access and modify weights and biases\n",
    "for i, layer in enumerate(th_policy_network.mlp_block):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        print(f\"Layer {i}:\")\n",
    "        print(\"Original weights:\", layer.weight.shape)\n",
    "        print(\"Original biases:\", layer.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weights_bias[\"params\"]['hidden_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:hidden_0------------------\n",
      "bias size: (512,)\n",
      "kernel size: (48, 512)\n",
      "layer:hidden_1------------------\n",
      "bias size: (256,)\n",
      "kernel size: (512, 256)\n",
      "layer:hidden_2------------------\n",
      "bias size: (128,)\n",
      "kernel size: (256, 128)\n",
      "layer:hidden_3------------------\n",
      "bias size: (24,)\n",
      "kernel size: (128, 24)\n"
     ]
    }
   ],
   "source": [
    "for key, values in weights_bias[\"params\"].items():\n",
    "    print(f\"layer:{key}------------------\")\n",
    "    for key, kernel_bias in values.items():\n",
    "        print(f\"{key} size: {kernel_bias.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Linear(in_features=48, out_features=512, bias=True)\n",
      "1 SiLU()\n",
      "2 Linear(in_features=512, out_features=256, bias=True)\n",
      "3 SiLU()\n",
      "4 Linear(in_features=256, out_features=128, bias=True)\n",
      "5 SiLU()\n",
      "6 Linear(in_features=128, out_features=24, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(th_policy_network.mlp_block):\n",
    "    print(i, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming th_policy_network is already defined\n",
    "values = [(key,value) for key, value in weights_bias[\"params\"].items()]\n",
    "j = 0\n",
    "for i, layer in enumerate(th_policy_network.mlp_block):\n",
    "    if isinstance(layer, nn.Linear):  # Check if the layer is a Linear layer\n",
    "        #print(f\"Layer {values[i][0]}:\")\n",
    "        #print(\"Weights shape:\", layer.weight.shape)\n",
    "        #print(\"Biases shape:\", layer.bias.shape)\n",
    "        #print(f\"before: {layer.weight.data}, size: {layer.weight.data.shape}\")\n",
    "        #print(f\"BEFOREvalues: {values[i][1]['kernel']}, size: {values[i][1]['kernel'].shape}\")\n",
    "\n",
    "        #print(f\"size: {values[i][1]['bias'].shape}\")\n",
    "        #print(f\"size: {values[i][1]['kernel'].shape}\")\n",
    "        if (i%2==0):\n",
    "            \n",
    "            transpose_tensor_kernel = torch.tensor(values[j][1]['kernel']).t()\n",
    "            transpose_tensor_bias = torch.tensor(values[j][1]['bias']).t()\n",
    "\n",
    "            #print(f\"ker: {transpose_tensor_kernel.shape}\")\n",
    "            #print(f\"bia: {transpose_tensor_bias.shape}\")\n",
    "                # Assign new weights and biases\n",
    "            layer.weight.data = transpose_tensor_kernel\n",
    "            layer.bias.data = transpose_tensor_bias\n",
    "            j = j + 1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "input = torch.randn(batch_size, 48)  # For a batch of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (activation): SiLU()\n",
       "  (mlp_block): Sequential(\n",
       "    (hidden_0): Linear(in_features=48, out_features=512, bias=True)\n",
       "    (activation_0): SiLU()\n",
       "    (hidden_1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (activation_1): SiLU()\n",
       "    (hidden_2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (activation_2): SiLU()\n",
       "    (hidden_3): Linear(in_features=128, out_features=24, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_policy_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1688,  0.8599,  0.9902,  0.1623, -0.0766, -0.3626,  0.7645,  0.9771,\n",
       "          0.9611,  0.8755, -0.2907, -0.5002]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_policy_network.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-5.3753e-03, -3.7227e-03,  8.1214e-03,  2.5784e-03, -6.0854e-03,\n",
       "         -1.6575e-03,  6.0498e-03, -1.8035e-03, -9.9622e-01,  9.2987e-05,\n",
       "          2.4611e-02,  1.0910e-01,  1.6130e-02,  1.2811e-02,  9.1156e-02,\n",
       "         -1.9285e-02,  9.3518e-03,  1.0188e-01,  3.8124e-02,  2.0091e-02,\n",
       "          8.4244e-02, -4.6906e-03,  8.9083e-03, -2.5855e-02,  5.9413e-03,\n",
       "          9.4363e-03, -2.6273e-02, -6.1056e-03,  4.4214e-03, -2.1119e-02,\n",
       "          6.9455e-03, -1.0700e-03, -6.9315e-03, -2.3088e-01, -3.0316e-02,\n",
       "          5.0119e-01,  2.5405e-01, -1.0623e-02,  5.2193e-01, -2.1492e-01,\n",
       "          5.4053e-02,  4.6472e-01,  2.5415e-01,  3.8651e-02,  4.8790e-01,\n",
       "         -2.9012e-03, -7.5254e-04, -1.1815e-04]),\n",
       " tensor([0.3682, 0.1376, 0.1472, 0.8580, 0.4785, 0.5599, 0.0573, 0.0689, 0.0445,\n",
       "         0.1033, 0.1173, 0.1269, 0.1088, 0.1202, 0.1283, 0.0904, 0.1269, 0.1364,\n",
       "         0.0931, 0.1213, 0.1330, 1.9139, 2.7987, 3.6095, 1.9457, 2.8429, 3.8450,\n",
       "         1.9158, 3.0908, 3.5546, 1.9811, 3.0042, 3.6406, 0.2244, 0.2634, 0.3063,\n",
       "         0.2250, 0.2627, 0.2920, 0.2180, 0.2518, 0.2937, 0.2017, 0.2596, 0.3026,\n",
       "         0.8305, 0.2875, 0.5342]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to sai.onnx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the output ONNX file path\n",
    "onnx_file_path = \"sai.onnx\"\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    th_policy_network,                  # Model to export\n",
    "    input,            # Dummy input\n",
    "    onnx_file_path,         # Output file path\n",
    "    export_params=True,     # Export model parameters (weights)\n",
    "    opset_version=11,       # ONNX opset version (e.g., 11 is widely supported)\n",
    "    do_constant_folding=True,  # Optimize the model by folding constants\n",
    "    input_names=[\"state\"],  # Input tensor name\n",
    "    output_names=[\"actions\"],  # Output tensor name\n",
    ")\n",
    "\n",
    "print(f\"Model exported to {onnx_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mjx_play",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
